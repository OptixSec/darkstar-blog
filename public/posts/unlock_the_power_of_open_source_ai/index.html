<!DOCTYPE html>
<html lang="en">

<head>
  <title>
  Unlock the Power of Open-Source AI: Installing Ollama, Fabric, and Running AI Locally · Darkstar Blog
</title>
  <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="color-scheme" content="light dark">




<meta name="author" content="Darkstar">
<meta name="description" content="A small guide about using the Fabric framework with locally ran AI">
<meta name="keywords" content="blog,developer,hobbyist,linux,it,hacking,security,tech,crypto,guides,opinions,personal">


  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Unlock the Power of Open-Source AI: Installing Ollama, Fabric, and Running AI Locally">
  <meta name="twitter:description" content="A small guide about using the Fabric framework with locally ran AI">

<meta property="og:url" content="https://optixsec.github.io/darkstar-blog/posts/unlock_the_power_of_open_source_ai/">
  <meta property="og:site_name" content="Darkstar Blog">
  <meta property="og:title" content="Unlock the Power of Open-Source AI: Installing Ollama, Fabric, and Running AI Locally">
  <meta property="og:description" content="A small guide about using the Fabric framework with locally ran AI">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-05-31T15:43:58+02:00">
    <meta property="article:modified_time" content="2024-05-31T15:43:58+02:00">
    <meta property="article:tag" content="Ollama">
    <meta property="article:tag" content="Fabric">




<link rel="canonical" href="https://optixsec.github.io/darkstar-blog/posts/unlock_the_power_of_open_source_ai/">


<link rel="preload" href="/fonts/fa-brands-400.woff2" as="font" type="font/woff2" crossorigin>
<link rel="preload" href="/fonts/fa-regular-400.woff2" as="font" type="font/woff2" crossorigin>
<link rel="preload" href="/fonts/fa-solid-900.woff2" as="font" type="font/woff2" crossorigin>


  
  
  <link rel="stylesheet" href="/darkstar-blog/css/coder.min.38c4552ac40f9ae3408bad40358f654ebd8804412fe74ed56f2d6c8a7af82dd3.css" integrity="sha256-OMRVKsQPmuNAi61ANY9lTr2IBEEv507Vby1sinr4LdM=" crossorigin="anonymous" media="screen" />






  
    
    
    <link rel="stylesheet" href="/darkstar-blog/css/coder-dark.min.a00e6364bacbc8266ad1cc81230774a1397198f8cfb7bcba29b7d6fcb54ce57f.css" integrity="sha256-oA5jZLrLyCZq0cyBIwd0oTlxmPjPt7y6KbfW/LVM5X8=" crossorigin="anonymous" media="screen" />
  



 




<link rel="icon" type="image/svg+xml" href="/img/favicon.svg" sizes="any">
<link rel="icon" type="image/png" href="/img/favicon-32x32.png" sizes="32x32">
<link rel="icon" type="image/png" href="/img/favicon-16x16.png" sizes="16x16">

<link rel="apple-touch-icon" href="/images/apple-touch-icon.png">
<link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">

<link rel="manifest" href="/site.webmanifest">
<link rel="mask-icon" href="/images/safari-pinned-tab.svg" color="#5bbad5">









</head>






<body class="preload-transitions colorscheme-auto">
  
<div class="float-container">
    <a id="dark-mode-toggle" class="colorscheme-toggle">
        <i class="fa-solid fa-adjust fa-fw" aria-hidden="true"></i>
    </a>
</div>


  <main class="wrapper">
    <nav class="navigation">
  <section class="container">
    
    <a class="navigation-title" href="https://optixsec.github.io/darkstar-blog/">
      Darkstar Blog
    </a>
    
    
      <input type="checkbox" id="menu-toggle" />
      <label class="menu-button float-right" for="menu-toggle">
        <i class="fa-solid fa-bars fa-fw" aria-hidden="true"></i>
      </label>
      <ul class="navigation-list">
        
          
            <li class="navigation-item">
              <a class="navigation-link " href="/darkstar-blog/posts/">Blog</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link " href="/darkstar-blog/about/">About</a>
            </li>
          
        
        
      </ul>
    
  </section>
</nav>


    <div class="content">
      
  <section class="container post">
    <article>
      <header>
        <div class="post-title">
          <h1 class="title">
            <a class="title-link" href="https://optixsec.github.io/darkstar-blog/posts/unlock_the_power_of_open_source_ai/">
              Unlock the Power of Open-Source AI: Installing Ollama, Fabric, and Running AI Locally
            </a>
          </h1>
        </div>
        <div class="post-meta">
          <div class="date">
            <span class="posted-on">
              <i class="fa-solid fa-calendar" aria-hidden="true"></i>
              <time datetime="2024-05-31T15:43:58&#43;02:00">
                May 31, 2024
              </time>
            </span>
            <span class="reading-time">
              <i class="fa-solid fa-clock" aria-hidden="true"></i>
              5-minute read
            </span>
          </div>
          <div class="authors">
  <i class="fa-solid fa-user" aria-hidden="true"></i>
    <a href="/darkstar-blog/authors/darkstar/">Darkstar</a></div>

          <div class="categories">
  <i class="fa-solid fa-folder" aria-hidden="true"></i>
    <a href="/darkstar-blog/categories/guides/">Guides</a></div>

          <div class="tags">
  <i class="fa-solid fa-tag" aria-hidden="true"></i>
    <span class="tag">
      <a href="/darkstar-blog/tags/ollama/">Ollama</a>
    </span>
      <span class="separator">•</span>
    <span class="tag">
      <a href="/darkstar-blog/tags/fabric/">Fabric</a>
    </span></div>

        </div>
      </header>

      <div class="post-content">
        
        <h2 id="unlock-the-power-of-open-source-ai-installing-ollama-fabric-and-running-ai-locally">
  Unlock the Power of Open-Source AI: Installing Ollama, Fabric, and Running AI Locally
  <a class="heading-link" href="#unlock-the-power-of-open-source-ai-installing-ollama-fabric-and-running-ai-locally">
    <i class="fa-solid fa-link" aria-hidden="true" title="Link to heading"></i>
    <span class="sr-only">Link to heading</span>
  </a>
</h2>
<p>I&rsquo;ve recently come across a really cool tool for interacting with AI models called <a href="https://github.com/danielmiessler/fabric"  class="external-link" target="_blank" rel="noopener">Fabric</a>. Fabric is an open-source framework created by <a href="https://github.com/danielmiessler/"  class="external-link" target="_blank" rel="noopener">Daniel Miessler</a> that can perform specific tasks using a large set of prompts. Today, I&rsquo;m going to show you how I installed it on my system together with <a href="https://ollama.com/"  class="external-link" target="_blank" rel="noopener">Ollama</a> to run AI locally and show some examples of Fabric in action.</p>
<h2 id="ollama">
  Ollama
  <a class="heading-link" href="#ollama">
    <i class="fa-solid fa-link" aria-hidden="true" title="Link to heading"></i>
    <span class="sr-only">Link to heading</span>
  </a>
</h2>
<h3 id="installing-ollama">
  Installing Ollama
  <a class="heading-link" href="#installing-ollama">
    <i class="fa-solid fa-link" aria-hidden="true" title="Link to heading"></i>
    <span class="sr-only">Link to heading</span>
  </a>
</h3>
<p>You can use Fabric with remote AI services like <a href="https://chatgpt.com/"  class="external-link" target="_blank" rel="noopener">ChatGPT</a>, but you also have the option to run a local model. I&rsquo;ve chosen a local model because I prioritize privacy. We&rsquo;ll download Ollama and the Llama3 AI model so we can employ Fabric to interact with it once we&rsquo;ve installed it later in this guide.</p>
<h4 id="ollama-linux-install-script">
  Ollama Linux Install Script
  <a class="heading-link" href="#ollama-linux-install-script">
    <i class="fa-solid fa-link" aria-hidden="true" title="Link to heading"></i>
    <span class="sr-only">Link to heading</span>
  </a>
</h4>
<p>The official Ollama website offers a convenient installation script for Linux users, which simplifies the process of downloading and installing Ollama while also setting it up as a service.</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>curl -fsSL https://ollama.com/install.sh | sh
</span></span></code></pre></div><p>To confirm that Ollama has been correctly installed type:</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>ollama -v
</span></span></code></pre></div><h3 id="configuring-ollama">
  Configuring Ollama
  <a class="heading-link" href="#configuring-ollama">
    <i class="fa-solid fa-link" aria-hidden="true" title="Link to heading"></i>
    <span class="sr-only">Link to heading</span>
  </a>
</h3>
<p>Ollama should be up and running now. We&rsquo;ll proceed to download the AI model we want to run on our computer:</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>ollama pull llama3:latest
</span></span></code></pre></div><p>This will download the latest version of llama3 to our computer. We can start the model by typing:</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>ollama run llama3:latest
</span></span></code></pre></div><p>If everything went succesfully we should get a prompt like this:</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>&gt;&gt;&gt; Send a message <span style="color:#ff7b72;font-weight:bold">(</span>/? <span style="color:#ff7b72">for</span> help<span style="color:#ff7b72;font-weight:bold">)</span>
</span></span></code></pre></div><p>You can have a little chat with the AI now if you want or you can type <code>/bye</code> to quit and proceed with setting up Fabric on your computer.</p>
<h2 id="fabric">
  Fabric
  <a class="heading-link" href="#fabric">
    <i class="fa-solid fa-link" aria-hidden="true" title="Link to heading"></i>
    <span class="sr-only">Link to heading</span>
  </a>
</h2>
<h3 id="installing-fabric">
  Installing Fabric
  <a class="heading-link" href="#installing-fabric">
    <i class="fa-solid fa-link" aria-hidden="true" title="Link to heading"></i>
    <span class="sr-only">Link to heading</span>
  </a>
</h3>
<p>Before installing Fabric, ensure you have at least <strong>Python 3.10</strong> or newer and <strong>pipx</strong> installed on your system.</p>
<h4 id="cloning-the-repo">
  Cloning the repo
  <a class="heading-link" href="#cloning-the-repo">
    <i class="fa-solid fa-link" aria-hidden="true" title="Link to heading"></i>
    <span class="sr-only">Link to heading</span>
  </a>
</h4>
<p>Decide where on your system you want to store the Fabric project. I decided to put it in <code>~/repos</code>. Now navigate to that directory:</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cd ~/repos/
</span></span></code></pre></div><p>Clone the Fabric repository to your current directory:</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>git clone https://github.com/danielmiessler/fabric.git
</span></span></code></pre></div><p>When done, navigate to the main Fabric directory:</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cd fabric/
</span></span></code></pre></div><h4 id="install-fabric">
  Install Fabric
  <a class="heading-link" href="#install-fabric">
    <i class="fa-solid fa-link" aria-hidden="true" title="Link to heading"></i>
    <span class="sr-only">Link to heading</span>
  </a>
</h4>
<p>Continue by installing Fabric on your computer by typing:</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>pipx install .
</span></span></code></pre></div><p>Run the setup script:</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>fabric --setup
</span></span></code></pre></div><p>Follow the instructions to add any API keys if desired. I suggest adding an API key for YouTube, as we&rsquo;ll be using it in one of the examples later. However, this is optional; you can proceed without adding any API keys and run the AI model locally. Now restart your shell to reload your configurations and test if Fabric is working by typing:</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>fabric --help
</span></span></code></pre></div><p>Before continuing, I&rsquo;ve created an alias inside my shell&rsquo;s configuration file called <code>clip</code>. This alias outputs the content of the clipboard to the terminal, allowing us to pipe that content into Fabric for running various patterns against it. We can also use tools like <code>cat</code> or <code>echo</code> to pipe the content of a file or string into Fabric. Having the ability to use <code>clip</code> to pipe the content of your clipboard is very handy though! If you want to set up the alias yourself, you can add the following line to your shell&rsquo;s configuration file:</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>alias <span style="color:#79c0ff">clip</span><span style="color:#ff7b72;font-weight:bold">=</span><span style="color:#a5d6ff">&#34;xclip -selection clipboard -o&#34;</span>
</span></span></code></pre></div><blockquote>
<p><strong>Note</strong>: You need to have <code>xclip</code> installed on your system for this alias to work.</p>
</blockquote>
<p>After reloading your config, we&rsquo;re now ready to start exploring Fabric.</p>
<h3 id="using-fabric">
  Using Fabric
  <a class="heading-link" href="#using-fabric">
    <i class="fa-solid fa-link" aria-hidden="true" title="Link to heading"></i>
    <span class="sr-only">Link to heading</span>
  </a>
</h3>
<p>Let&rsquo;s set the default model to <code>llama3:latest</code> so we don&rsquo;t have to specify which model we want to use everytime we use Fabric:</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>fabric --changeDefaultModel llama3:latest
</span></span></code></pre></div><p>Fabric uses patterns to complete various tasks, to get a list of available patterns, type:</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>fabric --list
</span></span></code></pre></div><p>Let&rsquo;s use Fabric to extract wisdom from the transcript of a YouTube video. I&rsquo;ll use <a href="https://youtu.be/HRAAzG_yDNY"  class="external-link" target="_blank" rel="noopener">this</a> YouTube video, which is about an upcoming NATO summit in Washington:</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>yt --transcript <span style="color:#a5d6ff">&#39;https://www.youtube.com/watch?v=JgsGH5IOCFE&#39;</span> | fabric -sp extract_wisdom
</span></span></code></pre></div><p><img src="/darkstar-blog/images/fabric_guide/extract_wisdom.png" alt="Example of how Fabric is used to extract wisdom from a YouTube video transcript."></p>
<p>Pretty awesome, right? The <code>-s</code> flag tells Fabric to stream the output. In other words, display the output of the command we gave it to the terminal. The <code>-p</code> flag tells Fabric which pattern we want to use against the input we gave it. Let&rsquo;s take it a step further and let Fabric write an essay based on the wisdom we extracted from the YouTube video by copying the output of the previous command and:</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>clip | fabric -sp write_essay
</span></span></code></pre></div><p><img src="/darkstar-blog/images/fabric_guide/write_essay.png" alt="Example of Fabric writing an essay about the wisdom we extracted from a YouTube video transcript"></p>
<p>You can also pipe multiple patterns together, which is called a stitch in Fabric&rsquo;s terms:</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>yt --transcript <span style="color:#a5d6ff">&#39;https://youtu.be/XNQhDl4a9Ko&#39;</span> | fabric -p extract_wisdom_agents | fabric -sp write_tweet
</span></span></code></pre></div><blockquote>
<p><strong>Note</strong>: <code>write_tweet</code> is a custom pattern I created myself. It still needs some tweaking.</p>
</blockquote>
<p><img src="/darkstar-blog/images/fabric_guide/stitching.png" alt="Example of stitching various Fabric patterns together"></p>
<h3 id="conclusion">
  Conclusion
  <a class="heading-link" href="#conclusion">
    <i class="fa-solid fa-link" aria-hidden="true" title="Link to heading"></i>
    <span class="sr-only">Link to heading</span>
  </a>
</h3>
<p>These are the basics of setting up Ollama, downloading and running an AI model on your local system, and using Fabric to augment your interactions with AI. There are many more patterns you can explore, but I&rsquo;ll leave that to you! I might do another guide in the future on how to create your own patterns and use them with Fabric. And don&rsquo;t forget to check out the Fabric documentation to discover more about how you can utilize Fabric. I hope you learned something, happy hacking!</p>

      </div>


      <footer>
        


        
        
        
        
        

        
        
      </footer>
    </article>

    
  </section>

    </div>

    <footer class="footer">
  <section class="container">
    ©
    
    2024
     Darkstar 
    ·
    
    Powered by <a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a> & <a href="https://github.com/luizdepra/hugo-coder/" target="_blank" rel="noopener">Coder</a>.
    
  </section>
</footer>

  </main>

  

  
  
  <script src="/darkstar-blog/js/coder.min.6ae284be93d2d19dad1f02b0039508d9aab3180a12a06dcc71b0b0ef7825a317.js" integrity="sha256-auKEvpPS0Z2tHwKwA5UI2aqzGAoSoG3McbCw73gloxc="></script>
  

  

  


  
  



  

  

  

  

  

  

  

  

  

  

  

  

  

  

  
</body>

</html>
